## **最佳 | 最佳论文花落谁家？**

本次会议的最佳论文是 CMU 的 "**SuRF:Practical Range Query Filtering with Fast Succinct Tries**”。布隆过滤器只适用于单行读取（Get）操作，实际业务场景中 OceanBase 可以通过对主键的前缀动态创建布隆过滤器来实现范围过滤功能。这种方法不够通用，论文中提出了一种新的数据结构，称为 FST（Fast Succint Tries），除了用于过滤单行读取，还可以用来过滤范围扫描（Scan）。FST 在之前的研究成果基础上做了进一步优化，很好地平衡了查询性能和内存占用，尤其适用于各种类 LSM 存储引擎。

论文中还尝试将 FST 集成到 RocksDB，单个 key 的存储空间只需要 10~14 个 bit，经济实用。最佳论文的第一作者是 **Huanchen Zhang**，是一个华人。**其实，SIGMOD 大会从 2015 年开始，每年最佳论文的第一作者都是华人**，2015 年的 Yufei Tao，2016 年的 Feifei Li，2017 年的 Wenfei Fan。PODS 的最佳论文是 “Entity Matching with Active Monotone Classification”，第一作者还是 YufeiTao。

## **最火 | 两大议题：Kubernetes & Machine Learning**

今年的两场 keynote 分别是 EricBrewer（Google）的 “Kubernetes and the New Cloud” 以及 Pedro Domingos（华盛顿大学）的 “Machine Learning for Data Management：Problems and Solutions”。去年的两场 keynote 分别是 OLTP 内存数据库以及 AQP 近似查询处理，聚焦在数据库领域本身，而今年两场 keynote 严格来讲都不属于数据库领域的范畴。

说实话，这两场 keynote 都没有给我留下特别深的印象。其中，Eric Brewer 的演讲大部分是 Kubernetes 的产品介绍。听演讲的过程中，我在思考一个问题：**阿里巴巴以及很多互联网公司也有类似的容器化产品，为什么 Google 最后成为了标准？**是因为技术，是因为生态，又或者是因为 Eric Brewer 等 Google 研发人员的业界影响力。这个问题我没有答案，我们需要不断地探索，才能明白满足某个公司、某个行业、甚至多个行业的需求与成为全行业事实标准之间的巨大鸿沟。

## **最前沿 | 数据库的五大发展趋势**

从数据库发展趋势的角度看，我认为今年 SIGMOD 主要体现在如下几个方面：云数据库、新型硬件，自治数据库、AI + 数据库，图数据库。

- **云数据库：**除了 EricBrewer 关于 Kubernetes 的 keynote，还有一个关于云数据库的 industry session。Amazon Aurora 从理论和实践上证明公有云场景可以重构关系数据库底层架构，Vertica 这样的老牌 OLAP 系统也上云了。
- **新型硬件：**存储介质从 SSD、大内存到非易失性内存，RDMA、GPU、FPGA 这样的硬件技术逐步普及。这次 SIGMOD 除了一场关于新硬件的 research session，即 “Databases for Emerging Hardware”，还有一场专门的 workshop DaMoN（DataManagement on New Hardware）。Oracle Labs 也有一个 RAPID 项目尝试做一个基于专用的数据处理芯片的 SQL 执行优化框架，不过通过内部交流了解到，专用硬件在 Oracle Labs 前景也不明确，RAPID 的项目不会集成到 Oracle 内核，只会考虑 MySQL。
- **自治数据库：**自治数据库在学术界和工业界都很热，Oracle 数据库最近几年最重要的研发工作就是自治数据库。CMU 的 Andrew Pavlo 团队这几年在学术界特别活跃，每年都能抓住热点并在 SIGMOD 和 VLDB 发表多篇论文，今年的最佳论文就是出自这个团队，他们在自治数据库上做的工作发表在 “Query-based Workload Forecasting for Self-Driving Database Management Systems”。
- **AI + 数据库：**这几年国内很多高校的数据库团队都转型大数据和 AI 了，北大数据库实验室在这次 SIGMOD 会议上也发表了两篇 AI 方向的论文，可见 AI 的火热。AI + System 是这两年兴起的一个热门方向，Google **Jeff Dean** 团队提出的 **Learned Index** 很好地利用 AI 统计实际数据的规律来设计更加高效的索引结构。这次 SIGMOD 除了 Learned Index 相关论文外，还有一个专门的关于机器学习的 research session“Machine Learning & Knowledge-base Construction”。目前的 AI 和数据库的结合还是比较浅的，未来是否可以用 AI 的方法来改进数据库内核的核心组件，例如优化器，这点我不太确定但充满期待。
- **图数据库：**去年 SIGMOD 的 best paper 就是关于图计算的 “Parallelizing Sequential Graph Computations”，第一作者是 Wenfei Fan，今年他们团队又发表了多篇关于图数据库的 paper，今年 SIGMOD 的 research session 和 industry session 都有关于图数据库的论文。

## **最独家 | 工业论文全揭秘**

整体上看，传统关系数据库内核的突破性工作变得越来越少，大部分研究工作是多个领域相结合的成果。相对来讲，工业界的实践类论文对于工程人员更有借鉴意义。下面是我对本次大会 industry session 八篇论文的解读。

***1."AmazonAurora: On Avoiding Distributed Consensus for I/Os, Commits, and Membership Changes"***

Aurora 团队在 2017 SIGMOD 会议上发表了 “Amazon Aurora: Design Considerations for High Throughput Cloud-Native Relational Databases”。

Aurora 数据库采用存储计算分离的技术架构，相比单机 MySQL/PostgreSQL 的主要优势有两点：**一是无损容灾**，将数据库容灾问题转化为更加成熟的分布式存储系统的容灾问题，而类 Paxos 协议在分布式存储中广泛使用；**二是存储可扩展**。存储单元是分布式的，可以很容易突破单机存储容量限制，而不需要涉及到复杂且性能更差的分布式事务。当然，事务是不可扩展的，Aurora 团队正在开发的 **Multi-Master** 功能用于**解决事务的扩展性问题**。

Aurora 提出了 “**the log is the database**” 的设计理念，数据库实例往底层存储只写 redo 日志，将日志回放等操作下推到底层存储，从而大大降低网络开销。去年 SIGMOD 的 Aurora 论文侧重点在于设计理念和整体架构，而今年 SIGMOD 的 Aurora 论文侧重几个关键点的实现方案，包括写流程和宕机恢复，快照读取，如何避免读取操作访问多数派副本，以及成员变更。Aurora 不需要使用两阶段提交协议，它的架构类似传统关系数据库的 Oracle RAC，并在 RAC 基础上通过日志下推到存储层来进一步优化。建议读者结合去年的 Aurora 论文一起阅读这篇论文，去年的论文相当于总体设计方案，今年的论文相当于最核心的几个模块的概要设计方案。

***2."\* ComputationReuse in Analytics Job Service at Microsoft "**

SCOPE 是微软的大数据处理平台，类似阿里巴巴的 MaxCompute。大数据平台一个常见的问题是有大量的重复计算，可能的原因包括 schema 设计不合理，用户互相拷贝脚本代码，等等。这篇论文提出了一个对重复计算进行在线物化的框架 CloudView，有两个主要的特点：一个是在线创建物化视图，另外一个是借鉴了关系数据库的渐进式优化思路（progressive query optimization），实现了反馈回路（feedbackloop），将运行时收集到的统计信息反馈到优化器。

作为一篇工业界论文，这篇文章还给出了很多 SCOPE 的运行数据和一些经验教训，对于阿里巴巴和其它大数据平台都有不错的借鉴意义。当然，物化视图里面有一个经典的难题，即在线更新的处理，这篇论文简单地将物化视图直接失效，这种做法还不够精细。

**3."Columnstoreand B+ tree - Are Hybrid Physical Designs Important?"**

HTAP 混合负载是工业界的一个热点，一般来说，**B + 树用于 OLTP 业务，列存用于 OLAP 业务**。然而，真实的业务场景中很难区分 workload 到底是 OLTP 还是 OLAP，主流的 OLTP 商业数据库都会有比较强的 OLAP 分析能力。这篇论文研究如何在同一个数据库中**混合使用 B + 树和列存这两种不同类型的索引**，它首先通过一个 benchmark 对这两种索引在各种读写场景下的性能做了一个量化对比，接着讲解 SQL Server 中使用的 Database Engine Tuning Advisor 来动态地选择和推荐索引。

论文最后的测试表明，Hybrid 方案的性能往往是优于单一的 B + 树或者列存的，不过这件事情最关键的点还在混合负载这一假设的适用范围，实际场景中我看到的 OLTP 业务往往只有很少一些分析型查询，而专门的 OLAP 业务往往几乎都是分析型查询。

***4."P-Store:An Elastic Database System with Predictive Provisioning"***

一般来讲，数据库的容量规划都是针对峰值压力，然而，每天高峰期和低峰期的压力差别非常之大，实际生产系统中在线服务的利用率也都很低。P-Store 提出，可以通过动态预测负载来提前对数据库扩容或者缩容，而不是等到负载发生变化之后再弹性伸缩。这篇论文最关键的地方在于提出了一个很有意思的 AI 和数据库相结合的问题，当然，论文中也给出了算法思路，即如何寻找一条具有最小成本的路径，使得系统有效能力总是大于实际需求。弹性伸缩有一个经典的难题，扩容 / 缩容操作的代价，在 share-nothing 架构中因为拷贝大量数据实用性不佳，往往更加适合存储计算分离的架构。互联网在线服务一般都可以借鉴 P-Store 的思路，当然，对于极端的场景，例如一年一次的双十一，流量突增到平常的几十倍甚至上百倍，我和论文作者在 Demo 环节做了简单交流，他们无法解决也不准备解决。

***5."Pinot:Realtime OLAP for 530 Million Users"***

Pinot 是 Linkedin 开源的一个大数据分析系统，类似 Apache Druid。Pinot 采用 Lambda 架构，将实时数据流和批处理数据分开处理，支持 Kafka 准实时数据写入以及 Hadoop 批量数据导入，支持类 SQL 查询。这篇论文介绍了 Pinot 的技术架构、查询执行流程、存储索引结构，等等。类似的产品比较多，包括 Apache 的 Druid 和 Kylin，Google Dremel 以及其开源实现 Apache Drill，其中，我认为技术做得最好的是 Google Dremel，值得深入研究，其它论文可以结合起来一起阅读。

***6."EonMode: Bringing the Vertica Columnar Database to the Cloud"\***

Vertica 是一个分析型数据库，底层存储分为两个部分，一部分为针对写优化的 WOS（Write Optimized Store），一部分为针对读优化的 ROS（Read Optimized Store），分别对应 LSM 存储引擎中的 MemTable 和 SSTable，且 ROS 采用列存实现，需要定期执行 Tuple Mover 操作，对应 LSM 存储引擎中的 compaction 操作。

Eon Mode 是 Vertica 的云版本，有两个主要的架构变化：一个是存储计算分离，抽象了一层通用的文件系统访问接口（UDFS API）支持本地文件系统或者 S3、HDFS 等通用分布式文件系统；还有一个是线性可扩展的分布式架构，支持动态扩容缩容，涉及的改造点包括数据划分、容错以及 SQL 优化和执行。采用存储计算分离架构后，Tuple Mover 操作也需要相应调整，以前的 Enterprise 版本每个副本都需要执行 Tuple Mover，现在只需要动态选择一个副本执行 Tuple Mover 即可。另外，Eon Mode 不再支持 WOS，不过我认为这是 Eon Mode 的实现问题导致的。

***7."Survivability of Cloud Databases -Factors and Prediction"***

这篇论文出自 Azure SQL Database 团队，提出了一个很好的问题：在公有云环境下预测一个数据库实例会在多久之后被删除，从而将数据库实例分成两类：short-lived（<=30 天）以及 long-lived（>30 天）。

论文中采用了机器学习中的**随机森林算法**，涉及的特征包括：实例创建时间（例如周末创建的实例很有可能由程序自动创建），数据库实例的名称（例如名字有意义的数据库实例存活时间相对更长），数据库大小，数据库版本升级频率，数据库实例类型（Basic / Standard / Premium），用户之前创建过的数据库实例存活时间，等等。这种分类对于云数据库的资源调度、用户隔离以及日常运营操作都有不错的指导意义。另外，这篇论文还给出了大量 Azure SQL DB 团队的运营数据，有很好的参考价值。

***8."RapidAdoption of Cloud Data Warehouse Technology Using Datometry Hyper-Q"***

数据库上云面临两个主要的问题：一个是数据库迁移，另外一个是应用程序迁移。对于第一点，各个云服务产商都有成熟的工具；对于第二点，目前没有成熟的解决方案。Hyper-Q 是一个可以将不同数据库系统的 SQL 请求互相翻译的中间件，目标是应用代码无需修改直接上云。

这件事情的难度很大，而且极其繁琐，论文中把 SQL 翻译分成三大类：1) Translation：简单的语法修改，例如关键词替换；2) Transformation：将用户查询转化为目标数据库类似的功能，并对结果做一定的处理，例如不同数据库的 NULL 列排序方式不同；3) Emulation：目标数据库没有类似的功能，需要在应用层模拟实现。演讲者对 Hyper-Q 的能力非常有自信，让人感觉是什么都能做，不过我并没有这么乐观，可能只是一个简单的数据类型或者语义的不同都需要做大量的工作，也可能带来严重的性能问题。