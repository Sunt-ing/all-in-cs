以前一直在做Flink，对Spark也略有了解，今天终于抽空把祖师爷——MapReduce原文给看了，就是那篇《MapReduce: simplified data processing on large clusters》。总体而言，感受如下：

- Google在2004年就有几千台机器专门负责MapReduce任务了，这集群也太大了吧，毕竟那是二十年前啊！
- 机器节点间的传输带宽居然有100-200GBPS！
- MapReduce模型和Map、Reduce这两个词的灵感居然是来自Lisp等函数式编程语言中的Map、Reduce原语，我还以为是来自MPI或者是数据库的Aggregate操作呢。
- 截止论文发表，遇到master节点单点失败时，MapReduce也只能通过master节点定期备份快照+出事时手动恢复master节点来解决。当初得知Hadoop早期只能这样时，我还以为是因为那时Hadoop实现得比较糟糕......
- 在当时，网络带宽是一种稀缺资源。网络带宽最重要这种想法很长一段时间里都在我的脑海中根深蒂固，直到近期我发现类似Amazon Aurora这种share everything的架构其实一个很根本的立足点就是局域网中的网络带宽已经非常高了，可能和磁盘读写相差无几。
- 早在那之前，人们就在考虑尽量在存储节点上计算了。
- 一个很有意思的参数：Map任务 200,000 个、Reduce任务 5000 个、worker机器 2000 个
- 那时候就提出了落伍者（straggler）这个概念，并且意识到straggler是很影响任务完成时间的了。同时，提出了一个通用的应对机制：遇到straggler时，额外使用一些worker进程来执行剩下的进行中的task。效果很好：在某个排序任务中，不使用这个机制的话可能会多花44%的时间。
- 那时，大家就对MapReduce做了一些优化，包括Combiner，即让Map端先简单reduce一下，再把这个reduce过的结果发给下游的Reduce端，从而减少发送的数据量，提高整个任务的处理速度。
- 有一些奇怪的处理方式，如：跳过损坏的record。如：用户程序中有一些bug导致Map或Reduce函数处理某些特定记录时总是出错，为了在debug完成前（有时甚至可能无法debug，如bug来自于某些不开源的依赖）完成任务，可以跳过这些records。如果不这样，可能不管再怎么重试也无法处理成功。
- 即使在这时候，这样的系统就有伪分布式部署、可视化监控网页、全局计数器的概念了。

- 感觉这篇文章真的讲的非常细，一些实现上的细节都说出来了，甚至放出了使用的源码样例，仿佛生怕你复现不出来。
- 首个版本的MapReduce库是2003年1月完成的，这年8月时又做了输入数据本地化、worker动态负载均衡等优化。我一开始还以为这玩意就花了几个星期就搞好了。
- 当时，MapReduce就被应用于大规模机器学习、从网页中抽取地理位置信息、图计算了。没想到啊没想到，他们当时居然真的拿这玩意做机器学习之类的，这些东西在现在其实都还是热门研究方向。这样看来，Mahout的存在，Spark GraphX的存在、Spark ML lib的热门（据说现在它在云上主要就是用来做机器学习）都是有来源的。不过，现在想想，Mahout支持的主要就是一些基础的统计机器学习方法，其实还是合理的。关于workload，另外一个想法就是其实在当时iterative算法就很常见了，并不需要等到Spark出现，如PageRank就是iterative的。
- Google在使用MapReduce前的索引计算代码行数达3800行，用后只有700行了。之前对索引系统的一个小更改可能要耗费几个月，现在只要几天。
- MapReduce这个框架的每一个点都不怎么新，但是把它们拼装在一起就是一个崭新的框架了，因为它相比于BSP（Bulk Synchronous Programming）、MPI实现了透明的容错处理。
- master在分配任务时，就考虑到了哪些机器已有哪些数据。

